<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <!-- <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/> -->
  <meta property="og:url" content="https://m-rewardbench.github.io"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" /> -->
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG"> -->
  <!-- <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
  <!-- <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="reward models, LLM, reward-bench">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>M-R·¥á·¥°·¥Ä Ä·¥ÖB·¥á…¥·¥Ñ ú : Evaluating Reward Models in Multilingual Settings</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <style>
        /* Base styling */
        .img_fit {
            display: block;
            margin-left: auto;
            margin-right: auto;
        }

        /* Fit height on wider screens */
        @media (min-aspect-ratio: 1/1) {
            .img_fit {
                height: 100vh;
                width: auto;
            }
        }

        /* Fit width on narrower screens */
        @media (max-aspect-ratio: 1/1) {
            .img_fit {
                width: 100vw;
                height: auto;
            }
        }
    </style>
  
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <span style="font-variant: small-caps;">M-RewardBench</span>: Evaluating Reward Models in Multilingual Settings
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://srishti-git1110.github.io/" target="_blank">Srishti Gureja</a><sup>‚ô¶1,5</sup>,</span>
              <span class="author-block">
                <a href="https://ljvmiranda921.github.io/" target="_blank">Lester James V. Miranda</a><sup>‚ô¶2</sup>,</span>
              <span class="author-block">
                <a href="https://shayekhbinislam.github.io/" target="_blank">Shayekh Bin Islam</a><sup>‚ô¶3,5</sup>,</span>
              <span class="author-block">
                <a href="https://rishabhmaheshwary.github.io/" target="_blank">Rishabh Maheshwary</a><sup>‚ô¶4</sup>,</span>
              <span class="author-block">
                <a href="https://medium.com/@drishtisharma96505" target="_blank">Drishti Sharma</a><sup>5</sup>,</span>
              <span class="author-block">
                <a href="https://id.linkedin.com/in/sang-gusti" target="_blank">Gusti Winata</a><sup>5</sup>,</span>
              
              <span class="author-block">
                <a href="https://www.natolambert.com/" target="_blank">Nathan Lambert</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://www.ruder.io/" target="_blank">Sebastian Ruder</a><sup>6</sup>,</span>
              <span class="author-block">
                <a href="https://www.sarahooker.me/" target="_blank">Sara Hooker</a><sup>7</sup>,</span>
              <span class="author-block">
                <a href="https://marziehf.github.io/" target="_blank">Marzieh Fadaee</a><sup>7</sup>
            </div>

            <div class="is-size-5 publication-authors">
              <!-- <span class="author-block">Institution Name<br>Conferance name and year</span> -->
              <span class="author-block"><sup>1</sup>Writesonic,</span>
              <span class="author-block"><sup>2</sup>Allen Institute for AI,</span>
              <span class="author-block"><sup>3</sup>Bangladesh University of Engineering and Technology,</span>
              <span class="author-block"><sup>4</sup>ServiceNow,</span>
              <span class="author-block"><sup>5</sup>Cohere For AI Community,</span>
              <span class="author-block"><sup>6</sup>Cohere,</span>
              <span class="author-block"><sup>7</sup>Cohere For AI</span>
              <span class="eql-cntrb"><small><br><sup>‚ô¶</sup>Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                    <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2410.15522.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Supplementary PDF link -->
              <!-- <span class="link-block">
                <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supplementary</span>
                </a>
              </span> -->

              <!-- Github link -->
              <span class="link-block">
                <a href="https://github.com/for-ai/m-rewardbench" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <!-- Hugging Face -->
              <span class="link-block">
                <a href="https://hf.co/datasets/C4AI-Community/multilingual-reward-bench" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <!-- <i class="fab fa-github"></i> -->
                    ü§ó
                  </span>
                  <span>Dataset</span>
                </a>
              </span>

              <!-- ArXiv abstract Link -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.15522" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv</span>
              </a>
              </span>
              <!-- Leaderboard -->
              <span class="link-block">
                <a href="https://c4ai-community-m-rewardbench.hf.space/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    üèÜ
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>

                
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        We conduct a systematic evaluation of several reward models in multilingual settings. Our findings reveal a significant gap in RM performance between English and nonEnglish languages and that RMs can have 
        different preferences across languages.
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
<!-- Reward models (RMs) have driven the state-of-the-art performance of LLMs today by enabling the integration of human feedback into the language modeling process. However, RMs are primarily trained and evaluated in English, and their capabilities in multilingual settings remain largely understudied. In this work, we conduct a systematic evaluation of several reward models in multilingual settings. We first construct the first-of-its-kind multilingual RM evaluation benchmark, 
<span style="font-variant: small-caps;">M-RewardBench</span>, consisting of 2.87k preference instances for 23 typologically diverse languages, that tests the chat, safety, reasoning, and translation capabilities of RMs. We then rigorously evaluate a wide range of reward models on 
<span style="font-variant: small-caps;">M-RewardBench</span>, offering fresh insights into their performance across diverse languages. We identify a significant gap in RMs' performances between English and non-English languages and show that RM preferences can change substantially from one language to another. We also present several findings on how different multilingual aspects impact RM performance. Specifically, we show that the performance of RMs is improved with improved translation quality. Similarly, we demonstrate that the models exhibit better performance for high-resource languages. We release 
<span style="font-variant: small-caps;">M-RewardBench</span> dataset and the codebase in this study to facilitate a better understanding of RM evaluation in multilingual settings.  -->
Reward models (RMs) have driven the state-of-the-art performance of LLMs today by enabling
the integration of human feedback into the language modeling process. However, RMs are
primarily trained and evaluated in English, and their capabilities in multilingual settings remain
largely understudied. In this work, we conduct a systematic evaluation of several 
reward models in multilingual settings. We first construct
the first-of-its-kind multilingual RM evaluation
benchmark, <span style="font-variant: small-caps;">M-RewardBench</span>, consisting of 2.87k preference instances for 23 typologically
diverse languages, that tests the chat, safety, reasoning, and translation capabilities of RMs.
We then rigorously evaluate a wide range of reward models on <span style="font-variant: small-caps;">M-RewardBench</span>, offering 
fresh insights into their performance across
diverse languages. We identify a significant
gap in RMs‚Äô performances between English
and non-English languages and show that RM
preferences can change substantially from one
language to another. We also present several
findings on how different multilingual aspects
impact RM performance. Specifically, we show
that the performance of RMs is improved with
improved translation quality. Similarly, we
demonstrate that the models exhibit better performance for high-resource languages. 
We release the <span style="font-variant: small-caps;">M-RewardBench</span> dataset and the
codebase in this study to facilitate a better 
understanding of RM evaluation in multilingual settings.

          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- <div id="results-carousel" class="carousel results-carousel"> -->
       <div class="item"> 
        <!-- Your image here -->
        <img src="static/images/eng_vs_m_gap.png"  
          class="img_fit"
          alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
          Performance gap between RewardBench (English) and the average M-REWARDBENCH scores
across 23 languages for various reward models (Pearson
r: 0.92, Spearman œÅ: 0.89). All models underperform
on our multilingual benchmark compared to their performance on the corresponding English benchmark.
        </h2> -->
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/mrb_full.png" 
        class="img_fit"
        alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
          Second image description.
        </h2> -->
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/maple_full.png"
        class="img_fit"
        alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
         Third image description.
       </h2> -->
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/inner_model_agreement.png"
      class="img_fit" 
      alt="MY ALT TEXT"/>
      <!-- <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2> -->
    </div>
  <!-- </div> -->
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{gureja2024mrewardbench,
          title={M-RewardBench: Evaluating Reward Models in Multilingual Settings}, 
          author={Srishti Gureja and Lester James V. Miranda and Shayekh Bin Islam and Rishabh Maheshwary and Drishti Sharma and Gusti Winata and Nathan Lambert and Sebastian Ruder and Sara Hooker and Marzieh Fadaee},
          year={2024},
          eprint={2410.15522},
          archivePrefix={arXiv},
          primaryClass={cs.CL},
          url={https://arxiv.org/abs/2410.15522}, 
    }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
